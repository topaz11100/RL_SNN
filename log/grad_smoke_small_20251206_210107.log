2025-12-06 21:01:09,062 - INFO - Args: {'scenario': 'grad', 'seed': 0, 'batch_size_images': 8, 'event_batch_size': 2048, 'run_name': 'smoke_small_20251206_210107_grad', 'log_interval': 1, 'num_epochs': 1, 'T_unsup1': 50, 'T_unsup2': 50, 'T_semi': 50, 'T_sup': 50, 'spike_array_len': 10, 'sigma_unsup1': 0.1, 'sigma_unsup2': 0.1, 'sigma_semi': 0.1, 'sigma_sup': 0.1, 'N_E': 32, 'N_hidden': 64, 'dt': 1.0, 'layer_index_scale': 1.0, 'lr_actor': 0.001, 'lr_critic': 0.001, 'ppo_eps': 0.2, 'ppo_epochs': 2, 'ppo_batch_size': 512, 'exc_clip_min': 0.0, 'exc_clip_max': 1.0, 'inh_clip_min': 0.0, 'inh_clip_max': 1.0, 'local_lr': 0.01, 'rho_target': 0.1, 'alpha_sparse': 1.0, 'alpha_div': 0.1, 'alpha_stab': 0.1, 'beta_margin': 0.5, 'alpha_align': 0.1, 'max_rate': 0.1, 'log_gradient_stats': True, 'result_dir': 'results/grad/smoke_small_20251206_210107_grad'}
2025-12-06 21:01:09,062 - INFO - Starting scenario: grad
2025-12-06 21:01:09,062 - INFO - Results will be saved to: results/grad/smoke_small_20251206_210107_grad
Traceback (most recent call last):
  File "/home/yongokhan/바탕화면/snn/RL_SNN/main.py", line 39, in <module>
    main()
  File "/home/yongokhan/바탕화면/snn/RL_SNN/main.py", line 35, in main
    runner(args, logger)
  File "/home/yongokhan/바탕화면/snn/RL_SNN/scenarios/grad_mimicry.py", line 267, in run_grad
    gather_events(
  File "/home/yongokhan/바탕화면/snn/RL_SNN/utils/event_utils.py", line 175, in gather_events
    states, extras = _build_states_and_extras(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yongokhan/바탕화면/snn/RL_SNN/utils/event_utils.py", line 57, in _build_states_and_extras
    pre_hist = _select_windows(padded_pre, batches, pre_idx, times, window)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yongokhan/바탕화면/snn/RL_SNN/utils/event_utils.py", line 21, in _select_windows
    return padded_spikes[batch_idx.unsqueeze(1), neuron_idx.unsqueeze(1), gather_times]
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.98 GiB. GPU 0 has a total capacity of 11.63 GiB of which 1.75 GiB is free. Including non-PyTorch memory, this process has 9.84 GiB memory in use. Of the allocated memory 9.69 GiB is allocated by PyTorch, and 25.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
