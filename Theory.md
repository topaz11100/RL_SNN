### 1. 연구 개요 및 목표

**1.1 전체 목표**

이 연구의 목표는 강화학습(Reinforcement Learning, RL) 에이전트를 이용해 스파이킹 신경망(Spiking Neural Network, SNN)의 **시냅스 가중치 업데이트 규칙(plasticity rule)** 을 학습시키는 것이다.

기존 STDP 식처럼 사람이 고정한 수식을 그대로 사용하는 대신, 각 시냅스를 **로컬 상태만 관측하는 RL 에이전트**로 보고 이 에이전트가

* 로컬 상태(local state)를 기반으로 **가중치 변경량(action)** 을 제안하고
* 전역 과제 성능 혹은 BPTT 기울기 등 **전역 신호를 보상(reward)** 으로 받아 학습

하도록 설계한다.

본 보고서는 이후 구현 보고서와 코드 구조의 기준이 되는 **고정된 실험 설계(구조, 타임스텝, 네트워크 아키텍처 포함)** 를 명시한다.

**1.2 실험 축**

실험은 두 축으로 구성한다.

1. **완전 비지도 설정에서의 구조·역할 창발(emergence)**
2. **지도 설정에서의 전역 기울기 근사(gradient mimicry)**

### 2. 공통 구성 요소

**2.1 데이터셋 및 입력 인코딩**

* 데이터셋

  * MNIST (28×28 회색조 이미지, 10 클래스)를 사용한다.

* 정규화

  * 각 픽셀 값을 [0, 1] 구간으로 정규화한다.

* 푸아송 인코더(Poisson encoder)

  * 각 픽셀 정규화 값 p ∈ [0, 1] 에 대해, 주어진 시간 길이 T 동안 픽셀마다 독립적인 푸아송 스파이크 열을 생성한다.
  * 시뮬레이션은 이산 시간 스텝으로 진행되며, 한 스텝마다 해당 픽셀에서 스파이크가 발생할 확률을 p 에 비례하도록 설정한다.

* 타임스텝 설정

  * 완전 비지도 실험 1 (창발)

    * 한 입력당 **T_unsup = 100 타임스텝** 동안 스파이크를 주입한다.
  * gradient mimicry 실험 2 (지도)

    * 한 입력당 **T_sup = 16 타임스텝** 동안 스파이크를 주입한다.

타임스텝 수 T_unsup, T_sup 은 실험 전체에서 고정된 상수로 사용한다.

**2.2 뉴런 모델(LIF)**

모든 스파이킹 층은 **LIF(Leaky Integrate-and-Fire)** 뉴런을 사용한다.

* 연속 시간 형태

  * τ_m dV/dt = −(V − V_rest) + R I_in
* 이산 시간 구현

  * 시뮬레이션은 타임스텝 Δt 단위로 진행하며, 각 스텝마다 다음과 같이 업데이트한다.

    * V(t+1) = V(t) + (Δt/τ_m)·(−(V(t) − V_rest) + R I_in(t))
  * 발화 조건

    * V(t+1) ≥ V_th 가 되면 스파이크를 발생시키고, 막전위를 V_reset 으로 리셋한다.

각 층별 τ_m, V_th, V_reset, R, Δt 등 하이퍼파라미터는 구현 단계에서 명시적으로 고정하여 사용한다.

**2.3 스파이크 히스토리 배열과 1D-CNN 입력 길이**

각 시냅스는 pre/post 스파이크 히스토리를 **최근 K 스텝 길이**로 유지하며, 이를 정책 입력 전단 1D-CNN 의 입력으로 사용한다.

* 시뮬레이션 타임스텝 수 T 와 실제로 CNN 에 전달되는 스파이크 히스토리 배열 길이 K 는 서로 다른 값으로 설정될 수 있다. 예를 들어, 시뮬레이션은 T 스텝 동안 수행하되, 최근 K 스텝만 잘라서 정책 입력으로 사용할 수 있다.
* 히스토리 배열이 실제로 관측된 스파이크 시퀀스를 넘지 않도록 항상 **K ≤ T** 를 만족하도록 설정한다.

구체적인 실험에서는 다음과 같이 설정한다.

* 완전 비지도 실험 1

  * 타임스텝 수 T_unsup = 100
  * 스파이크 히스토리 배열 길이 K_unsup = 100 (기본값, 일반적으로 1 ≤ K_unsup ≤ T_unsup)
  * 한 시냅스 i 의 입력 배열 크기

    * X_spike,i^(unsup)(t) ∈ R^(2×K_unsup)
  * 채널 2 는 각각 pre 뉴런, post 뉴런의 스파이크 시퀀스를 의미한다.

* gradient mimicry 실험 2

  * 타임스텝 수 T_sup = 16
  * 스파이크 히스토리 배열 길이 K_sup = 16 (기본값, 일반적으로 1 ≤ K_sup ≤ T_sup)
  * 한 시냅스 i 의 입력 배열 크기

    * X_spike,i^(sup)(t) ∈ R^(2×K_sup)

현재 설계에서는 단순화를 위해 K_unsup = T_unsup, K_sup = T_sup 로 두지만, 구현 측면에서는 T 와 K 를 독립적으로 조정하면서 항상 K ≤ T 제약만 유지하면 된다.

**2.4 1D-CNN 전단 구조(공통)**

스파이크 배열만 1D-CNN 으로 처리한다. CNN 전단은 두 실험에서 공통으로 사용하며, 시간 축 길이에 따라 입력 길이만 달라진다.

* 입력

  * 완전 비지도: 2×K_unsup 배열(기본값 2×100)
  * 지도: 2×K_sup 배열(기본값 2×16)

* 1D-CNN 구조

  1. Conv1

     * in_channels = 2
     * out_channels = 16
     * kernel_size = 5
     * padding = 2
     * stride = 1
     * 활성함수: ReLU
  2. Conv2

     * in_channels = 16
     * out_channels = 32
     * kernel_size = 5
     * padding = 2
     * stride = 1
     * 활성함수: ReLU
  3. Global average pooling (time 축 평균)

     * 출력 feature 벡터 h_i(t)의 차원은 32

CNN 전단은 **스파이크 시간 패턴만** 보고, 해당 시냅스 주변의 시계열 패턴을 요약한 feature 벡터 h_i(t) 를 생성한다.

**2.5 정책·가치 네트워크 입력 구성**

CNN 출력에 스칼라 정보를 concat 해서 MLP에 넣는 **late fusion** 구조를 사용한다.

* 공통 스칼라 입력

  * 해당 시냅스의 현재 가중치 w_i(t)

* 레이어 번호 l_norm,i

  * gradient mimicry 실험 2 에서만 사용한다.
  * 해당 시냅스가 속한 레이어 인덱스를 0~1 구간으로 정규화한 값이다.
  * 완전 비지도 실험 1 에서는 학습층이 사실상 단층이므로 l_norm 을 로컬 상태에서 사용하지 않는다.

* 완전 비지도 실험 1 에서의 정책·가치 입력 벡터

  * h_i(t) ∈ R^32, w_i(t) ∈ R
  * z_i^(unsup)(t) = [h_i(t); w_i(t)] ∈ R^33

* gradient mimicry 실험 2 에서의 정책·가치 입력 벡터

  * h_i(t) ∈ R^32, w_i(t) ∈ R, l_norm,i ∈ R
  * z_i^(sup)(t) = [h_i(t); w_i(t); l_norm,i] ∈ R^34

**2.6 정책 네트워크(Actor)**

정책 네트워크는 입력 벡터 z_i(t) 를 받아 연속 스칼라 출력 Δd_i(t) 를 생성한다.

* 입력 차원

  * 완전 비지도: 33
  * gradient mimicry: 34

* 구조

  1. FC1

     * input_size = 33 또는 34
     * hidden_size = 64
     * 활성함수: ReLU
  2. FC2

     * hidden_size = 64
     * 활성함수: ReLU
  3. FC3

     * hidden_size = 1
     * 활성함수: Tanh (출력을 [−1, 1] 범위로 제한)

* 파라미터 공유 구조

  * 별도로 명시하는 다중 정책 실험(예: 특정 층별·역할별로 서로 다른 정책을 두는 확장)을 제외하면, 하나의 정책 네트워크 π_θ 를 **전체 SNN 의 모든 뉴런/시냅스가 공유**하여 사용한다.
  * 즉, 각 시냅스마다 관측되는 로컬 상태 z_i(t) 는 다르지만, 사용되는 정책 파라미터 θ 는 전역적으로 하나이며, "모든 뉴런이 같은 정책을 따른다"는 의미에서 단일 정책 구조를 가정한다.

* 출력

  * Δd_i(t) = π_θ(z_i(t)) ∈ [−1, 1]

* 가중치 업데이트

  * 이벤트 기반으로 pre 또는 post 뉴런이 스파이크를 낸 타임스텝에서만 정책을 호출하고, 다음과 같이 업데이트한다.

    * w_i(t+1) = clip(w_i(t) + η·Δd_i(t), w_min, w_max)

**2.7 가치함수 네트워크(Critic)**

가치함수 네트워크는 동일한 입력 벡터 z_i(t) 를 받아 해당 상태에서의 기대 보상 값을 추정한다.

* 입력 차원

  * 완전 비지도: 33
  * gradient mimicry: 34

* 구조

  1. FC1

     * input_size = 33 또는 34
     * hidden_size = 64
     * 활성함수: ReLU
  2. FC2

     * hidden_size = 64
     * 활성함수: ReLU
  3. FC3

     * hidden_size = 1
     * 활성함수: 없음 (선형 출력)

* 파라미터 공유 구조

  * 가치함수 네트워크 V_φ 역시 하나의 네트워크를 전체 SNN 의 모든 뉴런/시냅스가 공유한다. 각 시냅스는 서로 다른 z_i(t) 를 넣어 같은 V_φ 를 질의한다.

* 출력

  * V_φ(z_i(t)) ∈ R
  * 완전 비지도 실험에서는 에피소드 전체 전역 보상 R 의 기댓값을, gradient mimicry 실험에서는 시간·시냅스별 보상 r_i,t 의 기대값을 근사하는 baseline 으로 사용한다.

1D-CNN 전단은 정책과 가치함수가 공유한다. z_i(t) 이후의 FC head 만 Actor 와 Critic 이 별도로 갖도록 구현한다.

**2.8 학습 알고리즘 개요(Actor–Critic)**

* 에피소드 진행 중

  1. 푸아송 인코더로 생성된 스파이크를 SNN에 주입하며 T_unsup 또는 T_sup 타임스텝 동안 시뮬레이션한다.
  2. pre 또는 post 스파이크 이벤트가 발생할 때마다 해당 시냅스에 대해

     * 스파이크 히스토리 배열 X_spike,i(t) 구성 (최근 K 스텝 기준)
     * 1D-CNN 을 통해 h_i(t) 계산
     * z_i(t) 구성 후 Δd_i(t) 및 V_φ(z_i(t)) 계산
     * 가중치 업데이트 수행
     * trajectory 로 (z_i(t), Δd_i(t), V_φ(z_i(t))) 를 저장

* 에피소드 종료 후

  * 완전 비지도 실험 1

    * 전역 보상 R 을 계산하고, 모든 이벤트에 대해 advantage A = R − V_φ(z_i(t)) 를 사용하여 Actor–Critic 업데이트를 수행한다.
  * gradient mimicry 실험 2

    * BPTT 로 각 시냅스·시간에 대한 기울기 g_i,t 를 계산한다.
    * 각 이벤트에 대해 보상 r_i,t 를 정의하고 advantage A_i,t = r_i,t − V_φ(z_i(t)) 로 Actor–Critic 업데이트를 수행한다.

* 정책 공유에 대한 정리

  * 별도 언급이 없는 한, 위 Actor–Critic 학습 과정에서 **하나의 정책·가치 네트워크 쌍이 전체 SNN 의 모든 뉴런/시냅스에 대해 공유**된다.
  * 특정 실험에서 여러 정책을 사용하는 변형(예: pre/post 분리 정책, 층별 정책 등)을 도입하는 경우, 해당 실험 섹션에서 예외를 명시적으로 기술한다.

### 3. 실험 1: 완전 비지도 설정에서의 구조·역할 창발

**3.1 목표**

완전 비지도(라벨, 기울기 등 지도 신호 없음) 설정에서, 설계자가

* 흥분성·억제성 뉴런 라벨을 지정하지 않고
* lateral inhibition 이나 고정된 E/I 구조를 강하게 가정하지 않은 상태에서

오직 **발화 통계와 안정성에 대한 전역 비지도 보상**만을 사용해 학습을 진행했을 때,

1. 시냅스 플라스틱 정책들이 서로 다른 기능적 역할(강화 중심, 억제·안정화 중심 등)로 자발적으로 분화하는지
2. 뉴런 집단 수준에서 일부 뉴런이 주로 양수 outgoing weight, 다른 뉴런이 주로 음수 outgoing weight 를 갖는 **E/I 유사 구조**가 자연스럽게 나타나는지

를 관찰한다.

**3.2 SNN 구조(완전 비지도)**

완전 비지도 실험에서 사용하는 SNN 구조는 다음과 같다.

* 입력층

  * MNIST 28×28 픽셀을 784 개의 입력 푸아송 스파이크 소스로 매핑한다.
  * 각 입력 샘플에 대해 T_unsup = 100 타임스텝 동안 스파이크를 주입한다.

* LIF 피처층(학습층)

  * 뉴런 수: N_feat = 400 으로 고정한다.
  * 입력층에서 피처층으로 향하는 모든 시냅스에 대해 RL 기반 플라스틱 정책을 적용한다.

* 억제 구조

  * lateral inhibition 또는 global inhibitory neuron 을 고정 scaffold 로 둘 수 있으며, 해당 가중치는 학습하지 않는다.
  * minimal bias 조건과 scaffold 부착 조건을 나누어 비교한다.

학습이 실제로 일어나는 층은 이 LIF 피처층 한 층이므로, 완전 비지도 실험에서는 레이어 번호 l_norm 을 로컬 상태에서 사용하지 않는다.

**3.3 로컬 상태와 정책 입력(완전 비지도)**

* 스파이크 히스토리 배열

  * 각 시냅스 i 는 pre/post 스파이크 히스토리를 길이 K_unsup 의 배열로 유지한다 (기본 설정에서는 K_unsup = 100).
  * CNN 입력 크기: X_spike,i^(unsup)(t) ∈ R^(2×K_unsup).

* 정책·가치 입력 벡터

  * CNN 전단을 통과하여 feature 벡터 h_i(t) ∈ R^32 를 얻는다.
  * 현재 가중치 w_i(t) 를 concat 하여

    * z_i^(unsup)(t) = [h_i(t); w_i(t)] ∈ R^33
  * 이 벡터를 정책 네트워크와 가치함수 네트워크가 공통 입력으로 사용한다.

**3.4 전역 비지도 보상**

전역 보상 R 은 다음 세 항의 가중합으로 정의한다.

* R = α_sparse R_sparse + α_div R_div + α_stab R_stab

* R_sparse

  * 각 입력 자극에 대해 발화한 뉴런 수가 적을수록 높은 값이 되도록 정의한다.

* R_div

  * 데이터셋 전체에 걸쳐 다양한 뉴런이 winner 로 선택될수록 높은 값이 되도록 정의한다.

* R_stab

  * 동일 입력을 반복 제시했을 때 winner 패턴이 안정적일수록 높은 값이 되도록 정의한다.

구체적인 수식(정규화 방식 등)은 구현 단계에서 고정하여 사용한다.

**3.5 학습 및 분석**

* 학습 절차

  1. 모든 시냅스 가중치와 정책·가치 네트워크 파라미터를 초기화한다.
  2. 각 에피소드(입력 샘플)에 대해 T_unsup = 100 타임스텝 동안 시뮬레이션을 수행한다.
  3. pre/post 이벤트 발생 시마다 정책을 호출해 가중치를 업데이트하고 trajectory 를 기록한다.
  4. 에피소드 종료 후 전역 보상 R 을 계산한다.
  5. 저장된 모든 이벤트에 대해 advantage A = R − V_φ(z_i(t)) 를 사용해 Actor–Critic 업데이트를 수행한다.

* 분석 항목

  1. 정책별 STDP 커널 Δw(Δt) 추출
  2. 뉴런별 outgoing weight sign 분포 분석을 통한 E/I 유사 구조 등장 여부 확인
  3. 두 정책이 강화 중심/안정화 중심 등으로 역할 분화하는지 통계 분석
  4. minimal bias 조건과 scaffold 조건에서 창발 패턴 비교

### 4. 실험 2: 전역 기울기 모방(gradient mimicry)

**4.1 목표**

지도 학습 환경에서, 로컬 SNN 플라스틱 정책이 **전역 BPTT 기울기**를 어느 정도까지 근사할 수 있는지 정량적으로 평가한다.

* 기준선 모델: surrogate gradient 기반 BPTT 로 학습한 다층 SNN
* 로컬 정책이 제안하는 업데이트 Δw_agent 가

  * 전역 기울기 g = ∂L/∂w 와 얼마나 잘 정렬되는지 (sign 일치, 코사인 유사도 등)
  * 실제 성능(정확도, loss 수렴 속도)에서 기준선과 얼마나 가까운지

를 측정한다.

**4.2 SNN 구조(gradient mimicry)**

gradient mimicry 실험에서 사용하는 SNN 구조는 다음과 같다.

* 입력층

  * MNIST 28×28 픽셀을 784 개의 입력 푸아송 스파이크 소스로 매핑한다.
  * 각 입력 샘플에 대해 T_sup = 16 타임스텝 동안 스파이크를 주입한다.

* 히든 LIF 층

  * 히든층 1: 256 뉴런
  * 히든층 2: 128 뉴런
  * 히든층 3: 64 뉴런
  * 히든층 4: 32 뉴런

* 출력층

  * 10 클래스 분류를 위한 출력 뉴런 10개

입력층을 제외하면 LIF 히든층 4개와 출력층 1개가 존재한다. 각 층 사이의 시냅스 가중치는 RL 정책 또는 BPTT 기준선에 따라 업데이트된다.

**4.3 로컬 상태와 정책 입력(gradient mimicry)**

* 스파이크 히스토리 배열

  * 각 시냅스 i 는 pre/post 스파이크 히스토리를 길이 K_sup 의 배열로 유지한다 (기본 설정에서는 K_sup = 16).
  * CNN 입력 크기: X_spike,i^(sup)(t) ∈ R^(2×K_sup).

* 레이어 번호 l_norm,i

  * 입력층 다음 히든층 1을 0.2, 히든층 2를 0.4, 히든층 3을 0.6, 히든층 4를 0.8, 출력층을 1.0 과 같이 정규화하여 사용한다.

* 정책·가치 입력 벡터

  * CNN 전단을 통과하여 feature 벡터 h_i(t) ∈ R^32 를 얻는다.
  * 현재 가중치 w_i(t) 와 l_norm,i 를 concat 하여

    * z_i^(sup)(t) = [h_i(t); w_i(t); l_norm,i] ∈ R^34
  * 이 벡터를 정책 네트워크와 가치함수 네트워크가 공통 입력으로 사용한다.

**4.4 로컬 보상 설계: gradient 정렬 기반 보상**

로컬 정책 학습에는 전역 기울기 g_i,t 를 Teacher 신호로 사용하는 **gradient 정렬 기반 보상**을 사용한다.

* 한 이벤트에서 시냅스 i 의 정책 출력이 제안한 업데이트를 Δw_agent,i,t 라 할 때, 전역 기울기 g_i,t 에 대해

  * r_i,t^grad = − g_i,t·Δw_agent,i,t

* 너무 큰 업데이트를 방지하기 위해 정규화 항을 포함한다.

  * r_i,t^total = − g_i,t·Δw_agent,i,t − λ·(Δw_agent,i,t)^2

보상 r_i,t^total 을 기준으로 Actor–Critic 업데이트를 수행하고, sign 일치 비율이나 코사인 유사도 등은 분석 지표로 사용한다.

**4.5 학습 및 분석**

* 학습 절차

  1. 기준선 BPTT 모델 학습

     * 동일한 SNN 구조를 사용하여 surrogate gradient 기반 BPTT 로 SNN 을 학습하고, 기준선 정확도와 loss 곡선을 확보한다.
  2. 로컬 정책 모델 학습

     * 동일한 SNN 구조를 사용하되, 가중치 업데이트는 RL 정책이 결정하도록 바꾼다.
     * 순전파·역전파는 그대로 수행하여 각 시냅스·시간에 대한 기울기 g_i,t 를 계산한다.
     * 각 이벤트에 대해 r_i,t^total 을 계산하고 trajectory 와 함께 Actor–Critic 업데이트를 수행한다.
  3. 평가

     * 에포크별 정확도, loss, 평균 보상 등을 기록하고 기준선과 비교한다.

* 분석 항목

  1. 기준선 BPTT 모델과 로컬 정책 모델의 학습 곡선 및 최종 정확도 비교
  2. 여러 시점에서 각 시냅스에 대해 g_i,t 와 Δw_agent,i,t 의 상관계수, 코사인 유사도, 부호 일치 비율을 계산하여 시간에 따른 정렬도 변화를 확인
  3. 레이어 번호 l_norm 에 따른 전략 차이 분석 (깊이에 따른 다른 업데이트 패턴이 학습되는지)
  4. l_norm 을 제거한 순수 로컬 버전과의 비교 실험으로, 레이어 정보가 gradient mimicry 에 얼마나 기여하는지 평가

### 5. 기대 기여 및 활용

* 완전 비지도 실험 1

  * 전역 비지도 보상만으로도 두 개의 로컬 플라스틱 정책이 서로 다른 기능적 역할로 분화하는지, 뉴런 집단 수준에서 E/I 유사 sign 구조가 창발하는지를 확인할 수 있다.

* gradient mimicry 실험 2

  * 로컬 SNN 플라스틱 규칙이 다층 SNN에서 전역 BPTT 기울기를 어느 정도까지 근사할 수 있는지, 깊이에 따른 gradient 패턴까지 포함하여 정량적으로 평가할 수 있다.

이 설계는 이후 구현 보고서와 코드 구조의 기준으로 사용한다.
